During training, I tried many different scenarios. 
For example trying out many learning rates, epoch values, different kinds of processes like logistic regression, classification, and finally;
Xgboost library and its hyperpramaters. 
I also had to analyse the biases of each model to find a stable one.
Here are some graphs comparing the results:
<img width="339" alt="Screenshot 2024-11-29 at 7 52 23 PM" src="https://github.com/user-attachments/assets/863a2920-e4dd-4bab-8414-8e53ded11945">
`learing rates`


<img width="536" alt="Screenshot 2024-11-29 at 7 52 37 PM" src="https://github.com/user-attachments/assets/756e2f34-ac7e-4729-8dbc-ee825546d229">

`Accuracy`

<img width="785" alt="Screenshot 2024-11-29 at 7 53 45 PM" src="https://github.com/user-attachments/assets/150c9b36-47a9-4a56-b586-f52c877901c1">


<img width="722" alt="Screenshot 2024-11-29 at 7 53 56 PM" src="https://github.com/user-attachments/assets/8f0ba47d-c83e-4ea2-bce5-d7de18677924">




<img width="703" alt="Screenshot 2024-11-29 at 7 54 05 PM" src="https://github.com/user-attachments/assets/05f6c225-edbe-4df7-bbc4-9dbfb964a70e">

And finally: 
Here I have graphed the final feature importance of the exported model:
<img width="657" alt="Screenshot 2024-11-29 at 7 54 43 PM" src="https://github.com/user-attachments/assets/9d8ebc91-6f0a-4444-901b-7597406a123a">

